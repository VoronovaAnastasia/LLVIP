[34m[1mhyperparameters: [0mlr0=0.01, lrf=0.1, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0
[34m[1mTensorBoard: [0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/
  0%|          | 0.00/89.3M [00:00<?, ?B/s]  2%|â–         | 1.47M/89.3M [00:00<00:06, 14.6MB/s]  8%|â–Š         | 7.54M/89.3M [00:00<00:04, 19.0MB/s] 13%|â–ˆâ–Ž        | 11.5M/89.3M [00:00<00:03, 22.7MB/s] 16%|â–ˆâ–Œ        | 14.2M/89.3M [00:00<00:03, 23.0MB/s] 19%|â–ˆâ–‰        | 17.1M/89.3M [00:00<00:03, 24.8MB/s] 22%|â–ˆâ–ˆâ–       | 20.0M/89.3M [00:00<00:02, 26.2MB/s] 26%|â–ˆâ–ˆâ–Œ       | 23.0M/89.3M [00:00<00:02, 27.7MB/s] 29%|â–ˆâ–ˆâ–‰       | 26.0M/89.3M [00:00<00:02, 28.7MB/s] 33%|â–ˆâ–ˆâ–ˆâ–Ž      | 29.1M/89.3M [00:00<00:02, 29.6MB/s] 36%|â–ˆâ–ˆâ–ˆâ–Œ      | 32.2M/89.3M [00:01<00:01, 30.5MB/s] 40%|â–ˆâ–ˆâ–ˆâ–‰      | 35.3M/89.3M [00:01<00:01, 31.1MB/s] 43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 38.5M/89.3M [00:01<00:01, 31.6MB/s] 47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 41.6M/89.3M [00:01<00:01, 32.1MB/s] 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 44.8M/89.3M [00:01<00:01, 32.3MB/s] 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 48.0M/89.3M [00:01<00:01, 32.5MB/s] 57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 51.3M/89.3M [00:01<00:01, 33.0MB/s] 61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 54.4M/89.3M [00:01<00:01, 33.1MB/s] 65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 57.7M/89.3M [00:01<00:00, 33.4MB/s] 68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 61.0M/89.3M [00:01<00:00, 33.7MB/s] 72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 64.2M/89.3M [00:02<00:00, 33.3MB/s] 76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 67.5M/89.3M [00:02<00:00, 33.7MB/s] 79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 70.8M/89.3M [00:02<00:00, 33.4MB/s] 83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 74.0M/89.3M [00:02<00:00, 32.7MB/s] 86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 77.1M/89.3M [00:02<00:00, 32.9MB/s] 90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 80.3M/89.3M [00:02<00:00, 32.6MB/s] 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 83.7M/89.3M [00:02<00:00, 33.5MB/s] 97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 86.9M/89.3M [00:02<00:00, 33.7MB/s]100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89.3M/89.3M [00:02<00:00, 33.2MB/s]
/home/avvoronova/.conda/envs/diploma/lib/python3.7/site-packages/torch/cuda/__init__.py:104: UserWarning: 
NVIDIA A100-SXM-80GB with CUDA capability sm_80 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.
If you want to use the NVIDIA A100-SXM-80GB GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
Overriding model.yaml nc=80 with nc=1

                 from  n    params  module                                  arguments                     
  0                -1  1      9344  models.common.Conv                      [4, 64, 6, 2, 2]              
  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 
  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              
  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 
  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              
  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 
  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             
  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               
  9                -1  1   2624512  models.common.SPPF                      [1024, 1024, 5]               
 10                -1  1    525312  models.common.Conv                      [1024, 512, 1, 1]             
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 12           [-1, 6]  1         0  models.common.Concat                    [1]                           
 13                -1  3   2757632  models.common.C3                        [1024, 512, 3, False]         
 14                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              
 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 16           [-1, 4]  1         0  models.common.Concat                    [1]                           
 17                -1  3    690688  models.common.C3                        [512, 256, 3, False]          
 18                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              
 19          [-1, 14]  1         0  models.common.Concat                    [1]                           
 20                -1  3   2495488  models.common.C3                        [512, 512, 3, False]          
 21                -1  1   2360320  models.common.Conv                      [512, 512, 3, 2]              
 22          [-1, 10]  1         0  models.common.Concat                    [1]                           
 23                -1  3   9971712  models.common.C3                        [1024, 1024, 3, False]        
 24      [17, 20, 23]  1     32310  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [256, 512, 1024]]
Model Summary: 468 layers, 46140598 parameters, 46140598 gradients

Transferred 606/613 items from yolov5l.pt
Scaled weight_decay = 0.0005
[34m[1moptimizer:[0m SGD with parameter groups 101 weight, 104 weight (no decay), 104 bias
[34m[1malbumentations: [0mBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), MedianBlur(always_apply=False, p=0.01, blur_limit=(3, 7)), ToGray(always_apply=False, p=0.01), CLAHE(always_apply=False, p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))
[34m[1malbumentations: [0mChannelShuffle(always_apply=False, p=1)
[34m[1mtrain: [0mweights=yolov5l.pt, cfg=, data=data/LLVIP.yaml, hyp=data/hyps/hyp.scratch.yaml, epochs=5, batch_size=16, imgsz=1280, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, evolve=None, bucket=, cache=None, image_weights=False, device=0, multi_scale=False, single_cls=False, adam=False, sync_bn=False, workers=8, project=runs/train, name=LLVIP_export_test, exist_ok=False, quad=False, linear_lr=False, label_smoothing=0.0, patience=100, freeze=0, save_period=-1, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest
[34m[1mgithub: [0mskipping check (not a git repository), for updates see https://github.com/ultralytics/yolov5
[34m[1mWeights & Biases: [0mrun 'pip install wandb' to automatically track and visualize YOLOv5 ðŸš€ runs (RECOMMENDED)
Downloading https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5l.pt to yolov5l.pt...

[34m[1mtrain: [0mScanning '/home/avvoronova/diploma/dataset/labels/train_inf.cache' images and labels... 10821 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10821/10821 [00:00<?, ?it/s][34m[1mtrain: [0mScanning '/home/avvoronova/diploma/dataset/labels/train_inf.cache' images and labels... 10821 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10821/10821 [00:00<00:00, 157592234.67it/s]
[34m[1mval: [0mScanning '/home/avvoronova/diploma/dataset/labels/val_inf.cache' images and labels... 1203 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1203/1203 [00:00<?, ?it/s][34m[1mval: [0mScanning '/home/avvoronova/diploma/dataset/labels/val_inf.cache' images and labels... 1203 found, 0 missing, 0 empty, 0 corrupted: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1203/1203 [00:00<00:00, 12071166.78it/s]
Image sizes 1280 train, 1280 val
Using 8 dataloader workers
Logging results to [1mruns/train/LLVIP_export_test[0m
Starting training for 5 epochs...

     Epoch   gpu_mem       box       obj       cls    labels  img_size
Plotting labels... 

[34m[1mautoanchor: [0mAnalyzing anchors... anchors/target = 4.29, Best Possible Recall (BPR) = 0.9998
  0%|          | 0/677 [00:00<?, ?it/s]Traceback (most recent call last):
  File "train.py", line 656, in <module>
    main(opt)
  File "train.py", line 552, in main
    train(opt.hyp, opt, device, callbacks)
  File "train.py", line 323, in train
    pred = model(imgs)  # forward
  File "/home/avvoronova/.conda/envs/diploma/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/avvoronova/diploma/LLVIP/yolov5/models/yolo.py", line 143, in forward
    return self._forward_once(x, profile, visualize)  # single-scale inference, train
  File "/home/avvoronova/diploma/LLVIP/yolov5/models/yolo.py", line 166, in _forward_once
    x = m(x)  # run
  File "/home/avvoronova/.conda/envs/diploma/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/avvoronova/diploma/LLVIP/yolov5/models/common.py", line 45, in forward
    return self.act(self.bn(self.conv(x)))
  File "/home/avvoronova/.conda/envs/diploma/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/avvoronova/.conda/envs/diploma/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py", line 136, in forward
    self.weight, self.bias, bn_training, exponential_average_factor, self.eps)
  File "/home/avvoronova/.conda/envs/diploma/lib/python3.7/site-packages/torch/nn/functional.py", line 2058, in batch_norm
    training, momentum, eps, torch.backends.cudnn.enabled
RuntimeError: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED
  0%|          | 0/677 [01:48<?, ?it/s]srun: error: cn-042: task 0: Exited with exit code 1
