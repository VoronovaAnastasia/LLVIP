YOLOv5 ðŸš€ 2022-4-18 torch 1.7.0 CUDA:0 (Tesla V100-SXM2-32GB, 32510.5MB)

Fusing layers... 
Model Summary: 213 layers, 7013974 parameters, 0 gradients
[34m[1mval: [0mdata=data/LLVIP.yaml, weights=['modelrgbi.pt'], batch_size=32, imgsz=1280, conf_thres=0.001, iou_thres=0.6, task=val, device=, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False
Traceback (most recent call last):
  File "val.py", line 360, in <module>
    main(opt)
  File "val.py", line 334, in main
    run(**vars(opt))
  File "/home/avvoronova/.conda/envs/diploma/lib/python3.7/site-packages/torch/autograd/grad_mode.py", line 26, in decorate_context
    return func(*args, **kwargs)
  File "val.py", line 149, in run
    model(torch.zeros(1, 3, imgsz, imgsz).to(device).type_as(next(model.parameters())))  # run once
  File "/home/avvoronova/.conda/envs/diploma/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/avvoronova/diploma/LLVIP/yolov5/models/yolo.py", line 143, in forward
    return self._forward_once(x, profile, visualize)  # single-scale inference, train
  File "/home/avvoronova/diploma/LLVIP/yolov5/models/yolo.py", line 166, in _forward_once
    x = m(x)  # run
  File "/home/avvoronova/.conda/envs/diploma/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/avvoronova/diploma/LLVIP/yolov5/models/common.py", line 48, in forward_fuse
    return self.act(self.conv(x))
  File "/home/avvoronova/.conda/envs/diploma/lib/python3.7/site-packages/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/home/avvoronova/.conda/envs/diploma/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 423, in forward
    return self._conv_forward(input, self.weight)
  File "/home/avvoronova/.conda/envs/diploma/lib/python3.7/site-packages/torch/nn/modules/conv.py", line 420, in _conv_forward
    self.padding, self.dilation, self.groups)
RuntimeError: Given groups=1, weight of size [32, 4, 6, 6], expected input[1, 3, 1280, 1280] to have 4 channels, but got 3 channels instead
srun: error: cn-018: task 0: Exited with exit code 1
